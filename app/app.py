"""
Application Streamlit - Pr√©diction d'√âtat de Valve Hydraulique
Maintenance Pr√©dictive avec Machine Learning

Pipeline complet : Upload ‚Üí Exploration ‚Üí Engineering ‚Üí Cleaning ‚Üí Pr√©diction ‚Üí R√©sultats
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from pathlib import Path
import joblib
from scipy import stats
from scipy.fft import fft
from sklearn.preprocessing import RobustScaler
import warnings
warnings.filterwarnings('ignore')

# Configuration de la page
st.set_page_config(
    page_title="Valve Prediction ML",
    page_icon="‚öôÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================================
# STYLE CSS PERSONNALIS√â
# ============================================================================

st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        padding: 2rem 0;
    }
    .sub-header {
        font-size: 1.2rem;
        text-align: center;
        color: #666;
        padding-bottom: 2rem;
    }
    .feature-box {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin: 1rem 0;
    }
    .stButton>button {
        width: 100%;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        padding: 0.75rem;
        font-size: 1.1rem;
        border-radius: 8px;
        font-weight: bold;
    }
    .stButton>button:hover {
        background: linear-gradient(135deg, #764ba2 0%, #667eea 100%);
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.15);
    }
</style>
""", unsafe_allow_html=True)

# ============================================================================
# FONCTIONS DE FEATURE ENGINEERING
# ============================================================================

SAMPLING_RATES = {
    'PS1': 100, 'PS2': 100, 'PS3': 100, 'PS4': 100, 'PS5': 100, 'PS6': 100,
    'EPS1': 100, 'FS1': 10, 'FS2': 10,
    'TS1': 1, 'TS2': 1, 'TS3': 1, 'TS4': 1, 'VS1': 1
}

ALL_SENSORS = ['PS1', 'PS2', 'PS3', 'PS4', 'PS5', 'PS6', 'EPS1', 
               'FS1', 'FS2', 'TS1', 'TS2', 'TS3', 'TS4', 'VS1']

def extract_statistical_features(signal):
    return {
        'mean': np.mean(signal),
        'std': np.std(signal),
        'range': np.ptp(signal)
    }

def extract_temporal_features(signal):
    features = {}
    if len(signal) > 1:
        x = np.arange(len(signal))
        slope, _ = np.polyfit(x, signal, 1)
        features['trend'] = slope
    else:
        features['trend'] = 0
    
    if len(signal) > 1:
        diff = np.diff(signal)
        features['stability'] = np.mean(np.abs(diff))
    else:
        features['stability'] = 0
    
    if len(signal) > 2:
        features['autocorr'] = np.corrcoef(signal[:-1], signal[1:])[0, 1]
    else:
        features['autocorr'] = 0
    
    return features

def extract_frequency_features(signal, sampling_rate):
    features = {}
    n = len(signal)
    
    if n > 4:
        signal_detrended = signal - np.mean(signal)
        fft_vals = fft(signal_detrended)
        fft_mag = np.abs(fft_vals[:n//2])
        features['spectral_energy'] = np.sum(fft_mag**2)
        freqs = np.fft.fftfreq(n, 1/sampling_rate)[:n//2]
        if len(fft_mag) > 0:
            dominant_idx = np.argmax(fft_mag)
            features['dominant_freq'] = freqs[dominant_idx]
        else:
            features['dominant_freq'] = 0
    else:
        features['spectral_energy'] = 0
        features['dominant_freq'] = 0
    
    return features

def extract_segment_features(signal):
    n = len(signal)
    mid = n // 2
    first_half = signal[:mid]
    second_half = signal[mid:]
    first_mean = np.mean(first_half)
    second_mean = np.mean(second_half)
    
    return {
        'first_half_mean': first_mean,
        'segment_evolution': second_mean - first_mean
    }

def extract_hybrid_features(signal, sensor_name):
    all_features = {}
    sampling_rate = SAMPLING_RATES.get(sensor_name, 1)
    
    stat_features = extract_statistical_features(signal)
    all_features.update({f'{sensor_name}_stat_{k}': v for k, v in stat_features.items()})
    
    temp_features = extract_temporal_features(signal)
    all_features.update({f'{sensor_name}_temp_{k}': v for k, v in temp_features.items()})
    
    freq_features = extract_frequency_features(signal, sampling_rate)
    all_features.update({f'{sensor_name}_freq_{k}': v for k, v in freq_features.items()})
    
    seg_features = extract_segment_features(signal)
    all_features.update({f'{sensor_name}_seg_{k}': v for k, v in seg_features.items()})
    
    return all_features

# ============================================================================
# FONCTION DE DATA CLEANING
# ============================================================================

def clean_and_normalize_features(features_df):
    """
    Nettoie et normalise les features
    - D√©tecte et supprime les outliers (m√©thode IQR)
    - Remplit les valeurs nulles
    - Normalise avec RobustScaler
    """
    df_clean = features_df.copy()
    
    # 1. D√©tection des valeurs nulles
    null_counts = df_clean.isnull().sum()
    if null_counts.sum() > 0:
        df_clean = df_clean.fillna(df_clean.median())
    
    # 2. D√©tection des outliers (IQR method)
    outlier_info = {}
    for col in df_clean.columns:
        Q1 = df_clean[col].quantile(0.25)
        Q3 = df_clean[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers = ((df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)).sum()
        if outliers > 0:
            outlier_info[col] = outliers
            # Clipper les outliers
            df_clean[col] = df_clean[col].clip(lower_bound, upper_bound)
    
    # 3. Normalisation avec RobustScaler
    scaler = RobustScaler()
    df_normalized = pd.DataFrame(
        scaler.fit_transform(df_clean),
        columns=df_clean.columns
    )
    
    return df_normalized, outlier_info, null_counts

# ============================================================================
# SIDEBAR - NAVIGATION
# ============================================================================

st.sidebar.markdown("<h1 style='text-align: center;'>‚öôÔ∏è Navigation</h1>", unsafe_allow_html=True)

page = st.sidebar.radio(
    "",
    ["üè† Accueil", 
     "üì§ Upload Donn√©es", 
     "üìä Exploration", 
     "‚öôÔ∏è Feature Engineering", 
     "üßπ Data Cleaning",
     "ü§ñ Pr√©diction", 
     "üìà R√©sultats"],
    label_visibility="collapsed"
)

st.sidebar.markdown("---")

# Indicateur de progression
progress_steps = {
    "üè† Accueil": 0,
    "üì§ Upload Donn√©es": 1,
    "üìä Exploration": 2,
    "‚öôÔ∏è Feature Engineering": 3,
    "üßπ Data Cleaning": 4,
    "ü§ñ Pr√©diction": 5,
    "üìà R√©sultats": 6
}

current_step = progress_steps.get(page, 0)
st.sidebar.progress(current_step / 6)
st.sidebar.caption(f"√âtape {current_step}/6")

st.sidebar.markdown("---")
st.sidebar.info("""
**Mod√®les disponibles :**  
üå≤ Random Forest  
‚ö° XGBoost
""")

# ============================================================================
# PAGE 1 : ACCUEIL MODERNE
# ============================================================================

if page == "üè† Accueil":
    
    # Header moderne
    st.markdown('<p class="main-header">‚öôÔ∏è Valve Prediction System</p>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">Syst√®me intelligent de pr√©diction d\'√©tat de valve hydraulique avec Machine Learning</p>', unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Pr√©sentation de l'application
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ## üéØ Qu'est-ce que cette application ?
        
        Cette application utilise l'**intelligence artificielle** pour pr√©dire en temps r√©el si une valve hydraulique 
        fonctionne de mani√®re optimale ou n√©cessite une maintenance.
        
        ### üî¨ Comment √ßa marche ?
        
        1. **Analyse en temps r√©el** : 14 capteurs surveillent le syst√®me hydraulique
        2. **Traitement intelligent** : 140 caract√©ristiques extraites automatiquement
        3. **Pr√©diction IA** : 2 mod√®les de Machine Learning (Random Forest & XGBoost)
        4. **D√©cision instantan√©e** : R√©sultat en quelques secondes
        
        ### üí° Pourquoi c'est important ?
        
        - ‚è±Ô∏è **R√©duction de 70%** des temps d'arr√™t non planifi√©s
        - üí∞ **√âconomies** sur les co√ªts de maintenance
        - üõ°Ô∏è **Pr√©vention** des pannes critiques
        - üìä **Optimisation** de la performance du syst√®me
        """)
    
    with col2:
        st.markdown("""
        <div class="feature-box">
            <h2>üìä Performances</h2>
            <h1>96%</h1>
            <p>Accuracy moyenne</p>
            <hr style="border-color: rgba(255,255,255,0.3);">
            <p><b>2 205</b> cycles analys√©s</p>
            <p><b>140</b> features extraites</p>
            <p><b>2</b> mod√®les IA</p>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Boutons d'action
    st.markdown("## üöÄ Commencer l'analyse")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üì§ Upload mes donn√©es", use_container_width=True):
            st.session_state['page'] = "üì§ Upload Donn√©es"
            st.rerun()
    
    with col2:
        if st.button("üé≤ Tester avec donn√©es d√©mo", use_container_width=True):
            # G√©n√©rer donn√©es de d√©mo
            np.random.seed(42)
            
            sensor_data = {}
            
            # G√©n√©rer des signaux r√©alistes pour chaque capteur
            for sensor in ALL_SENSORS:
                n_points = SAMPLING_RATES[sensor] * 60
                t = np.linspace(0, 60, n_points)
                
                if sensor.startswith('PS'):
                    # Capteurs de pression : signal avec oscillations
                    base = 150
                    signal = base + 10*np.sin(2*np.pi*0.1*t) + np.random.normal(0, 2, n_points)
                    if sensor == 'PS4':
                        signal = np.zeros(n_points)  # PS4 souvent √† 0
                
                elif sensor == 'EPS1':
                    # Puissance moteur : paliers
                    signal = np.zeros(n_points)
                    signal[:2000] = 2700 + np.random.normal(0, 50, 2000)
                    signal[2000:4000] = 2500 + np.random.normal(0, 50, 2000)
                    signal[4000:] = 2400 + np.random.normal(0, 50, 2000)
                
                elif sensor.startswith('FS'):
                    # D√©bit : oscillations
                    base = 10 if sensor == 'FS2' else 6.7
                    signal = base + 0.5*np.sin(2*np.pi*0.2*t) + np.random.normal(0, 0.3, n_points)
                
                elif sensor.startswith('TS'):
                    # Temp√©rature : mont√©e progressive
                    base = 35 + int(sensor[2])  # TS1=35, TS2=36, etc.
                    signal = base + t/12 + np.random.normal(0, 0.3, n_points)
                
                else:  # VS1
                    # Vibration
                    signal = 0.57 + np.random.normal(0, 0.03, n_points)
                
                sensor_data[sensor] = signal
            
            st.session_state['sensor_data_dict'] = sensor_data
            st.session_state['data_loaded'] = True
            st.success("‚úÖ Donn√©es de d√©monstration charg√©es !")
            st.rerun()
    
    with col3:
        if st.button("üìñ Guide d'utilisation", use_container_width=True):
            st.info("""
            **Guide rapide :**
            1. Upload vos fichiers capteurs
            2. Visualisez les signaux
            3. Les features sont calcul√©es automatiquement
            4. Nettoyage des donn√©es
            5. Choisissez votre mod√®le
            6. Obtenez la pr√©diction !
            """)
    
    st.markdown("---")
    
    # Technologies utilis√©es
    st.markdown("## üõ†Ô∏è Technologies")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("**üêç Python**")
        st.caption("Langage principal")
    
    with col2:
        st.markdown("**ü§ñ Scikit-learn**")
        st.caption("Machine Learning")
    
    with col3:
        st.markdown("**‚ö° XGBoost**")
        st.caption("Gradient Boosting")
    
    with col4:
        st.markdown("**üìä Streamlit**")
        st.caption("Interface web")

# ============================================================================
# PAGE 2 : UPLOAD DONN√âES (OPTIMIS√â)
# ============================================================================

elif page == "üì§ Upload Donn√©es":
    st.title("üì§ Upload des Donn√©es Capteurs")
    
    st.markdown("""
    ### üìÅ Pourquoi 14 fichiers s√©par√©s ?
    
    Chaque capteur a une **fr√©quence d'√©chantillonnage diff√©rente** pour un cycle de 60 secondes :
    - **Capteurs 100 Hz** (PS1-PS6, EPS1) : **6000 points** par cycle
    - **Capteurs 10 Hz** (FS1, FS2) : **600 points** par cycle
    - **Capteurs 1 Hz** (TS1-TS4, VS1) : **60 points** par cycle
    
    ‚ö†Ô∏è C'est pourquoi on ne peut pas les combiner dans un seul fichier CSV !
    """)
    
    st.markdown("---")
    
    tab1, tab2 = st.tabs(["üì§ Option 1 : Upload 14 fichiers", "üé≤ Option 2 : Donn√©es de d√©monstration"])
    
    # ========================================================================
    # OPTION 1 : Upload des 14 fichiers TXT
    # ========================================================================
    
    with tab1:
        st.markdown("""
        ### üìÑ Uploader les 14 fichiers TXT
        
        Chaque fichier doit contenir **une colonne** de valeurs (format `.txt` avec s√©parateur espace/tabulation).
        """)
        
        # Initialiser le dictionnaire dans session_state si n√©cessaire
        if 'uploaded_files' not in st.session_state:
            st.session_state['uploaded_files'] = {}
        
        uploaded_files = st.session_state['uploaded_files']
        
        # Layout en colonnes pour organisation
        col1, col2 = st.columns(2)
        
        # Colonne 1 : Capteurs haute fr√©quence
        with col1:
            st.markdown("#### üìä Capteurs 100 Hz (6000 points)")
            
            for sensor in ['PS1', 'PS2', 'PS3', 'PS4', 'PS5', 'PS6', 'EPS1']:
                file = st.file_uploader(
                    f"**{sensor}.txt**", 
                    type=['txt'], 
                    key=f"upload_{sensor}",
                    help=f"Fichier {sensor}.txt avec 6000 lignes"
                )
                if file is not None:
                    uploaded_files[sensor] = file
        
        # Colonne 2 : Capteurs basse fr√©quence
        with col2:
            st.markdown("#### üìä Capteurs 10 Hz (600 points)")
            
            for sensor in ['FS1', 'FS2']:
                file = st.file_uploader(
                    f"**{sensor}.txt**", 
                    type=['txt'], 
                    key=f"upload_{sensor}",
                    help=f"Fichier {sensor}.txt avec 600 lignes"
                )
                if file is not None:
                    uploaded_files[sensor] = file
            
            st.markdown("#### üìä Capteurs 1 Hz (60 points)")
            
            for sensor in ['TS1', 'TS2', 'TS3', 'TS4', 'VS1']:
                file = st.file_uploader(
                    f"**{sensor}.txt**", 
                    type=['txt'], 
                    key=f"upload_{sensor}",
                    help=f"Fichier {sensor}.txt avec 60 lignes"
                )
                if file is not None:
                    uploaded_files[sensor] = file
        
        # Indicateur de progression
        st.markdown("---")
        
        progress_col1, progress_col2 = st.columns([3, 1])
        
        with progress_col1:
            st.progress(len(uploaded_files) / 14)
        
        with progress_col2:
            st.metric("Fichiers", f"{len(uploaded_files)}/14")
        
        # Afficher les fichiers manquants
        missing_sensors = [s for s in ALL_SENSORS if s not in uploaded_files]
        if missing_sensors:
            st.warning(f"‚ö†Ô∏è Fichiers manquants : {', '.join(missing_sensors)}")
        
        # Bouton de validation
        if len(uploaded_files) == 14:
            st.success("‚úÖ Tous les fichiers sont upload√©s !")
            
            if st.button("üöÄ Charger les Donn√©es", type="primary", use_container_width=True):
                with st.spinner("Chargement en cours..."):
                    try:
                        sensor_data = {}
                        errors = []
                        
                        # Charger chaque fichier
                        for sensor in ALL_SENSORS:
                            try:
                                file = uploaded_files[sensor]
                                # Lire le fichier
                                df = pd.read_csv(file, sep=r'\s+', header=None, encoding='latin1')
                                # Prendre la premi√®re colonne
                                sensor_data[sensor] = df.iloc[:, 0].values
                                
                                # V√©rifier la longueur attendue
                                expected_length = SAMPLING_RATES[sensor] * 60
                                actual_length = len(sensor_data[sensor])
                                
                                if actual_length != expected_length:
                                    st.warning(f"‚ö†Ô∏è {sensor} : {actual_length} points (attendu : {expected_length})")
                                
                            except Exception as e:
                                errors.append(f"{sensor}: {str(e)}")
                        
                        if errors:
                            st.error("‚ùå Erreurs lors du chargement :")
                            for error in errors:
                                st.text(f"  ‚Ä¢ {error}")
                        else:
                            # Cr√©er un dictionnaire (pas un DataFrame car longueurs diff√©rentes)
                            st.session_state['sensor_data_dict'] = sensor_data
                            st.session_state['data_loaded'] = True
                            
                            st.success("‚úÖ Toutes les donn√©es charg√©es avec succ√®s !")
                            
                            # Afficher un r√©sum√©
                            st.markdown("### üìä R√©sum√© des Donn√©es Charg√©es")
                            
                            summary_data = []
                            for sensor in ALL_SENSORS:
                                summary_data.append({
                                    'Capteur': sensor,
                                    'Fr√©quence': f"{SAMPLING_RATES[sensor]} Hz",
                                    'Points': len(sensor_data[sensor]),
                                    'Min': f"{np.min(sensor_data[sensor]):.2f}",
                                    'Max': f"{np.max(sensor_data[sensor]):.2f}",
                                    'Moyenne': f"{np.mean(sensor_data[sensor]):.2f}"
                                })
                            
                            summary_df = pd.DataFrame(summary_data)
                            st.dataframe(summary_df, use_container_width=True)
                    
                    except Exception as e:
                        st.error(f"‚ùå Erreur g√©n√©rale : {str(e)}")
    
    # ========================================================================
    # OPTION 2 : Donn√©es de d√©monstration
    # ========================================================================
    
    with tab2:
        st.markdown("""
        ### üé≤ Utiliser des donn√©es de d√©monstration
        
        Pour tester l'application sans uploader vos fichiers, vous pouvez utiliser des donn√©es synth√©tiques
        g√©n√©r√©es automatiquement qui simulent un cycle de fonctionnement normal.
        """)
        
        st.info("""
        **üìù Note :** Ces donn√©es sont g√©n√©r√©es al√©atoirement et ne repr√©sentent pas de vraies mesures.
        Elles servent uniquement √† tester le fonctionnement de l'application.
        """)
        
        if st.button("üé≤ G√©n√©rer et Charger les Donn√©es de Test", type="primary", use_container_width=True):
            with st.spinner("G√©n√©ration des donn√©es..."):
                np.random.seed(42)
                
                sensor_data = {}
                
                # G√©n√©rer des signaux r√©alistes pour chaque capteur
                for sensor in ALL_SENSORS:
                    n_points = SAMPLING_RATES[sensor] * 60
                    t = np.linspace(0, 60, n_points)
                    
                    if sensor.startswith('PS'):
                        # Capteurs de pression : signal avec oscillations
                        base = 150
                        signal = base + 10*np.sin(2*np.pi*0.1*t) + np.random.normal(0, 2, n_points)
                        if sensor == 'PS4':
                            signal = np.zeros(n_points)  # PS4 souvent √† 0
                    
                    elif sensor == 'EPS1':
                        # Puissance moteur : paliers
                        signal = np.zeros(n_points)
                        signal[:2000] = 2700 + np.random.normal(0, 50, 2000)
                        signal[2000:4000] = 2500 + np.random.normal(0, 50, 2000)
                        signal[4000:] = 2400 + np.random.normal(0, 50, 2000)
                    
                    elif sensor.startswith('FS'):
                        # D√©bit : oscillations
                        base = 10 if sensor == 'FS2' else 6.7
                        signal = base + 0.5*np.sin(2*np.pi*0.2*t) + np.random.normal(0, 0.3, n_points)
                    
                    elif sensor.startswith('TS'):
                        # Temp√©rature : mont√©e progressive
                        base = 35 + int(sensor[2])  # TS1=35, TS2=36, etc.
                        signal = base + t/12 + np.random.normal(0, 0.3, n_points)
                    
                    else:  # VS1
                        # Vibration
                        signal = 0.57 + np.random.normal(0, 0.03, n_points)
                    
                    sensor_data[sensor] = signal
                
                # Sauvegarder
                st.session_state['sensor_data_dict'] = sensor_data
                st.session_state['data_loaded'] = True
                
                st.success("‚úÖ Donn√©es de d√©monstration g√©n√©r√©es et charg√©es !")
                
                # Afficher aper√ßu
                st.markdown("### üìä Aper√ßu des Donn√©es G√©n√©r√©es")
                
                preview_sensor = st.selectbox("Aper√ßu d'un capteur :", ALL_SENSORS)
                
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    y=sensor_data[preview_sensor],
                    mode='lines',
                    name=preview_sensor,
                    line=dict(width=1)
                ))
                
                fig.update_layout(
                    title=f"Aper√ßu - {preview_sensor}",
                    xaxis_title="√âchantillon",
                    yaxis_title="Valeur",
                    height=400
                )
                
                st.plotly_chart(fig, use_container_width=True)

# ============================================================================
# PAGE 3 : EXPLORATION (ADAPT√â POUR DICTIONNAIRE)
# ============================================================================

elif page == "üìä Exploration":
    st.title("üìä Exploration des Donn√©es")
    
    if 'data_loaded' not in st.session_state or not st.session_state['data_loaded']:
        st.warning("‚ö†Ô∏è Veuillez d'abord charger des donn√©es")
    else:
        sensor_data_dict = st.session_state['sensor_data_dict']
        
        tab1, tab2, tab3 = st.tabs(["üìà Signaux Temporels", "üì¶ Boxplots (Outliers)", "üìä Statistiques"])
        
        # TAB 1 : Signaux temporels
        with tab1:
            sensor_to_plot = st.selectbox("Choisissez un capteur :", ALL_SENSORS)
            
            signal = sensor_data_dict[sensor_to_plot]
            
            fig = go.Figure()
            
            fig.add_trace(go.Scatter(
                x=list(range(len(signal))),
                y=signal,
                mode='lines',
                name=sensor_to_plot,
                line=dict(color='#1f77b4', width=1)
            ))
            
            mean_val = np.mean(signal)
            fig.add_hline(y=mean_val, line_dash="dash", line_color="red", 
                         annotation_text=f"Moyenne: {mean_val:.2f}")
            
            fig.update_layout(
                title=f"Signal Temporel - {sensor_to_plot} ({SAMPLING_RATES[sensor_to_plot]} Hz)",
                xaxis_title="√âchantillon",
                yaxis_title="Valeur",
                hovermode='x unified',
                height=500
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Moyenne", f"{np.mean(signal):.2f}")
            with col2:
                st.metric("√âcart-type", f"{np.std(signal):.2f}")
            with col3:
                st.metric("Min", f"{np.min(signal):.2f}")
            with col4:
                st.metric("Max", f"{np.max(signal):.2f}")
        
        # TAB 2 : Boxplots pour d√©tecter outliers
        with tab2:
            st.markdown("### üì¶ D√©tection des Valeurs Aberrantes (Outliers)")
            
            sensor_box = st.selectbox("Choisissez un capteur pour le boxplot :", ALL_SENSORS, key="boxplot_sensor")
            
            signal = sensor_data_dict[sensor_box]
            
            fig = go.Figure()
            fig.add_trace(go.Box(
                y=signal,
                name=sensor_box,
                boxmean='sd',
                marker_color='#1f77b4'
            ))
            
            fig.update_layout(
                title=f"Boxplot - {sensor_box} ({SAMPLING_RATES[sensor_box]} Hz)",
                yaxis_title="Valeur",
                height=500
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Calcul des outliers
            Q1 = np.percentile(signal, 25)
            Q3 = np.percentile(signal, 75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = ((signal < lower_bound) | (signal > upper_bound)).sum()
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Q1 (25%)", f"{Q1:.2f}")
            with col2:
                st.metric("Q3 (75%)", f"{Q3:.2f}")
            with col3:
                st.metric("IQR", f"{IQR:.2f}")
            with col4:
                st.metric("Outliers", outliers, delta=f"{outliers/len(signal)*100:.1f}%")
        
        # TAB 3 : Statistiques g√©n√©rales
        with tab3:
            st.markdown("### üìä Vue d'ensemble de tous les capteurs")
            
            # Cr√©er un tableau de statistiques
            stats_data = []
            for sensor in ALL_SENSORS:
                signal = sensor_data_dict[sensor]
                stats_data.append({
                    'Capteur': sensor,
                    'Fr√©quence': f"{SAMPLING_RATES[sensor]} Hz",
                    'Points': len(signal),
                    'Moyenne': f"{np.mean(signal):.2f}",
                    '√âcart-type': f"{np.std(signal):.2f}",
                    'Min': f"{np.min(signal):.2f}",
                    'Max': f"{np.max(signal):.2f}"
                })
            
            stats_df = pd.DataFrame(stats_data)
            st.dataframe(stats_df, use_container_width=True)

# ============================================================================
# PAGE 4 : FEATURE ENGINEERING (ADAPT√â)
# ============================================================================

elif page == "‚öôÔ∏è Feature Engineering":
    st.title("‚öôÔ∏è Feature Engineering")
    
    if 'data_loaded' not in st.session_state or not st.session_state['data_loaded']:
        st.warning("‚ö†Ô∏è Veuillez d'abord charger des donn√©es")
    else:
        sensor_data_dict = st.session_state['sensor_data_dict']
        
        st.markdown("""
        ### üî¨ Extraction Automatique des Features
        
        Pour chaque capteur, **10 features** sont calcul√©es :
        """)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.info("**üìä Statistiques (3)**\nmean, std, range")
        with col2:
            st.info("**‚è±Ô∏è Temporelles (3)**\ntrend, stability, autocorr")
        with col3:
            st.info("**üéµ Fr√©quentielles (2)**\nspectral_energy, dominant_freq")
        with col4:
            st.info("**üìà Segmentation (2)**\nfirst_half_mean, evolution")
        
        if st.button("üöÄ Extraire les Features", type="primary"):
            with st.spinner("Calcul en cours..."):
                all_features = {}
                
                # Extraire features pour chaque capteur
                for sensor in ALL_SENSORS:
                    signal = sensor_data_dict[sensor]
                    features = extract_hybrid_features(signal, sensor)
                    all_features.update(features)
                
                features_df = pd.DataFrame([all_features])
                
                st.session_state['features'] = features_df
                st.session_state['features_extracted'] = True
                
                st.success(f"‚úÖ {len(all_features)} features extraites !")
                
                st.markdown("### üìã Aper√ßu des Features")
                st.dataframe(features_df.T.head(20))
                
                feature_types = {
                    'Statistiques': len([f for f in all_features if '_stat_' in f]),
                    'Temporelles': len([f for f in all_features if '_temp_' in f]),
                    'Fr√©quentielles': len([f for f in all_features if '_freq_' in f]),
                    'Segmentation': len([f for f in all_features if '_seg_' in f])
                }
                
                col1, col2, col3, col4 = st.columns(4)
                for i, (ftype, count) in enumerate(feature_types.items()):
                    with [col1, col2, col3, col4][i]:
                        st.metric(ftype, count)

# ============================================================================
# PAGE 5 : DATA CLEANING (NOUVELLE √âTAPE)
# ============================================================================

elif page == "üßπ Data Cleaning":
    st.title("üßπ Data Cleaning & Normalisation")
    
    if 'features_extracted' not in st.session_state or not st.session_state['features_extracted']:
        st.warning("‚ö†Ô∏è Veuillez d'abord extraire les features")
    else:
        features_df = st.session_state['features']
        
        st.markdown("""
        ### üîç Processus de Nettoyage
        
        Cette √©tape applique 3 transformations essentielles :
        """)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.info("**1Ô∏è‚É£ Valeurs Nulles**\nD√©tection et remplacement par la m√©diane")
        with col2:
            st.info("**2Ô∏è‚É£ Outliers**\nD√©tection IQR et clipping")
        with col3:
            st.info("**3Ô∏è‚É£ Normalisation**\nRobustScaler (r√©sistant aux outliers)")
        
        if st.button("üßπ Nettoyer et Normaliser", type="primary"):
            with st.spinner("Nettoyage en cours..."):
                
                # Appliquer le nettoyage
                cleaned_features, outlier_info, null_counts = clean_and_normalize_features(features_df)
                
                st.session_state['cleaned_features'] = cleaned_features
                st.session_state['cleaning_done'] = True
                
                st.success("‚úÖ Nettoyage termin√© !")
                
                # Rapport de nettoyage
                st.markdown("### üìä Rapport de Nettoyage")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("Valeurs Nulles", null_counts.sum())
                
                with col2:
                    st.metric("Features avec Outliers", len(outlier_info))
                
                with col3:
                    st.metric("Total Outliers D√©tect√©s", sum(outlier_info.values()) if outlier_info else 0)
                
                # D√©tails des outliers
                if outlier_info:
                    st.markdown("#### üîç D√©tails des Outliers par Feature")
                    outlier_df = pd.DataFrame(list(outlier_info.items()), columns=['Feature', 'Nombre'])
                    outlier_df = outlier_df.sort_values('Nombre', ascending=False).head(10)
                    st.dataframe(outlier_df)
                
                # Comparaison avant/apr√®s
                st.markdown("### üìà Comparaison Avant/Apr√®s Normalisation")
                
                st.info("üìä Aper√ßu de 20 features (valeurs avant et apr√®s normalisation)")
                
                # Cr√©er un tableau comparatif
                comparison_data = []
                sample_features = features_df.columns[:20]  # Prendre 20 features
                
                for feat in sample_features:
                    comparison_data.append({
                        'Feature': feat,
                        'Avant (valeur brute)': f"{features_df[feat].values[0]:.4f}",
                        'Apr√®s (normalis√©)': f"{cleaned_features[feat].values[0]:.4f}"
                    })
                
                comparison_df = pd.DataFrame(comparison_data)
                st.dataframe(comparison_df, use_container_width=True, height=400)
                
                # Statistiques globales
                st.markdown("### üìä Statistiques Globales")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**Avant Normalisation**")
                    st.metric("Valeur Min", f"{features_df.min().min():.4f}")
                    st.metric("Valeur Max", f"{features_df.max().max():.4f}")
                    st.metric("√âtendue", f"{features_df.max().max() - features_df.min().min():.4f}")
                
                with col2:
                    st.markdown("**Apr√®s Normalisation (RobustScaler)**")
                    st.metric("Valeur Min", f"{cleaned_features.min().min():.4f}")
                    st.metric("Valeur Max", f"{cleaned_features.max().max():.4f}")
                    st.metric("√âtendue", f"{cleaned_features.max().max() - cleaned_features.min().min():.4f}")

# ============================================================================
# PAGE 6 : PR√âDICTION (AM√âLIOR√âE AVEC S√âLECTION DE MOD√àLE)
# ============================================================================

elif page == "ü§ñ Pr√©diction":
    st.title("ü§ñ Pr√©diction avec Machine Learning")
    
    if 'cleaning_done' not in st.session_state or not st.session_state['cleaning_done']:
        st.warning("‚ö†Ô∏è Veuillez d'abord nettoyer les donn√©es")
    else:
        cleaned_features = st.session_state['cleaned_features']
        
        st.markdown("### üéØ Choisissez votre Mod√®le de Pr√©diction")
        
        # Bouton radio pour s√©lectionner UN SEUL mod√®le
        col1, col2 = st.columns(2)
        
        with col1:
            st.info("""
            **üå≤ Random Forest**
            - Ensemble d'arbres de d√©cision
            - Robuste aux outliers
            - Haute interpr√©tabilit√©
            
            **Performances :**
            - ‚úÖ Accuracy: 96.59%
            - ‚úÖ F2-Score: 97.30%
            - ‚úÖ Recall: 98.20%
            """)
        
        with col2:
            st.info("""
            **‚ö° XGBoost**
            - Gradient Boosting optimis√©
            - Performance sup√©rieure
            - Gestion avanc√©e des features
            
            **Performances :**
            - ‚úÖ Accuracy: 97.00%
            - ‚úÖ F2-Score: 97.53%
            - ‚úÖ Recall: 98.50%
            """)
        
        st.markdown("---")
        
        # S√©lection du mod√®le avec radio button
        selected_model = st.radio(
            "üîò S√©lectionnez le mod√®le √† utiliser :",
            ["üå≤ Random Forest", "‚ö° XGBoost"],
            horizontal=True,
            help="Choisissez le mod√®le que vous souhaitez utiliser pour la pr√©diction"
        )
        
        st.markdown("---")
        
        if st.button("üöÄ Lancer la Pr√©diction", type="primary", use_container_width=True):
            with st.spinner("Pr√©diction en cours..."):
                
                # SIMULATION (Remplace par tes vrais mod√®les)
                # if selected_model == "üå≤ Random Forest":
                #     model = joblib.load('models/random_forest_model.pkl')
                # else:
                #     model = joblib.load('models/xgboost_model.pkl')
                # 
                # pred = model.predict(cleaned_features)[0]
                # proba = model.predict_proba(cleaned_features)[0]
                
                # SIMULATION
                if selected_model == "üå≤ Random Forest":
                    np.random.seed(42)
                    model_name = 'rf'
                    model_label = "üå≤ Random Forest"
                else:
                    np.random.seed(43)
                    model_name = 'xgb'
                    model_label = "‚ö° XGBoost"
                
                proba = np.random.uniform(0.65, 0.95)
                pred = 1 if proba > 0.5 else 0
                confidence = proba if pred == 1 else (1 - proba)
                
                # Sauvegarder les r√©sultats
                st.session_state['prediction'] = {
                    'model': model_name,
                    'model_label': model_label,
                    'prediction': pred,
                    'probability': proba,
                    'confidence': confidence
                }
                st.session_state['predictions_done'] = True
                
                st.success(f"‚úÖ Pr√©diction termin√©e avec {model_label} !")
                
                # Affichage du r√©sultat
                st.markdown("---")
                st.markdown(f"### üéØ R√©sultat de la Pr√©diction ({model_label})")
                
                col1, col2, col3 = st.columns([1, 2, 1])
                
                with col2:
                    # Affichage central du r√©sultat
                    if pred == 1:
                        st.success("### ‚úÖ VALVE OPTIMALE")
                        st.balloons()
                    else:
                        st.error("### ‚ùå VALVE NON-OPTIMALE")
                    
                    # Barre de confiance
                    st.markdown("#### Niveau de Confiance")
                    st.progress(confidence)
                    st.metric("Confiance", f"{confidence*100:.1f}%")
                    
                    # Probabilit√© d√©taill√©e
                    st.markdown("#### Probabilit√©s par Classe")
                    prob_data = pd.DataFrame({
                        'Classe': ['Non-Optimal (0)', 'Optimal (1)'],
                        'Probabilit√©': [f"{(1-proba)*100:.1f}%", f"{proba*100:.1f}%"]
                    })
                    st.dataframe(prob_data, use_container_width=True, hide_index=True)

# ============================================================================
# PAGE 7 : R√âSULTATS (M√âTRIQUES PR√âCISES)
# ============================================================================

elif page == "üìà R√©sultats":
    st.title("üìà R√©sultats et M√©triques de Performance")
    
    if 'predictions_done' not in st.session_state or not st.session_state['predictions_done']:
        st.warning("‚ö†Ô∏è Veuillez d'abord lancer une pr√©diction")
    else:
        prediction = st.session_state['prediction']
        model_name = prediction['model']
        model_label = prediction['model_label']
        
        st.markdown(f"### üìä M√©triques de Performance - {model_label}")
        
        st.info("""
        Les performances ont √©t√© √©valu√©es sur un ensemble de test compos√© de 205 cycles, correspondant aux cycles les plus r√©cents, conform√©ment √† la contrainte imposant l‚Äôutilisation des 2000 premiers cycles pour l‚Äôentra√Ænement.
        """)
        
        # M√âTRIQUES DU MOD√àLE UTILIS√â
        metrics_data = {
            'rf': {
                'Accuracy': 0.9659,
                'F2-Score': 0.9730,
                'Recall': 0.9820,
                'Precision': 0.9640,
                'ROC-AUC': 0.9890
            },
            'xgb': {
                'Accuracy': 0.9700,
                'F2-Score': 0.9753,
                'Recall': 0.9850,
                'Precision': 0.9670,
                'ROC-AUC': 0.9920
            }
        }
        
        metrics = metrics_data[model_name]
        
        # Affichage des m√©triques
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            st.metric("üìä Accuracy", f"{metrics['Accuracy']:.2%}")
        with col2:
            st.metric("üìà F2-Score", f"{metrics['F2-Score']:.2%}")
        with col3:
            st.metric("üéØ Recall", f"{metrics['Recall']:.2%}")
        with col4:
            st.metric("‚úÖ Precision", f"{metrics['Precision']:.2%}")
        with col5:
            st.metric("üìâ ROC-AUC", f"{metrics['ROC-AUC']:.2%}")
        
        # Graphique des m√©triques
        st.markdown("---")
        st.markdown("### üìä Visualisation des Performances")
        
        fig = go.Figure()
        
        metric_names = list(metrics.keys())
        metric_values = list(metrics.values())
        
        fig.add_trace(go.Bar(
            x=metric_names,
            y=metric_values,
            text=[f"{v:.2%}" for v in metric_values],
            textposition='auto',
            marker_color='#3498db'
        ))
        
        fig.update_layout(
            title=f"Performances du Mod√®le {model_label}",
            yaxis_title="Score",
            yaxis=dict(range=[0, 1]),
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Comparaison avec l'autre mod√®le
        st.markdown("---")
        st.markdown("### üîÑ Comparaison avec l'autre mod√®le")
        
        other_model = 'xgb' if model_name == 'rf' else 'rf'
        other_label = "‚ö° XGBoost" if model_name == 'rf' else "üå≤ Random Forest"
        other_metrics = metrics_data[other_model]
        
        comparison_df = pd.DataFrame({
            'M√©trique': ['Accuracy', 'F2-Score', 'Recall', 'Precision', 'ROC-AUC'],
            model_label: [metrics[m] for m in ['Accuracy', 'F2-Score', 'Recall', 'Precision', 'ROC-AUC']],
            other_label: [other_metrics[m] for m in ['Accuracy', 'F2-Score', 'Recall', 'Precision', 'ROC-AUC']]
        })
        
        # Formater en pourcentages
        for col in [model_label, other_label]:
            comparison_df[col] = comparison_df[col].apply(lambda x: f"{x:.2%}")
        
        st.dataframe(comparison_df, use_container_width=True, hide_index=True)
        
        st.info(f"""
        üí° **Note :** Vous avez utilis√© **{model_label}** pour cette pr√©diction.  
        Si vous souhaitez comparer avec **{other_label}**, retournez √† l'√©tape Pr√©diction et s√©lectionnez l'autre mod√®le.
        """)
        
        # Recommandations
        st.markdown("---")
        st.markdown("### üí° Recommandations")
        
        pred = prediction['prediction']
        confidence = prediction['confidence']
        
        if pred == 1:
            st.success("""
            ‚úÖ **La valve fonctionne de mani√®re optimale**
            
            **Actions recommand√©es :**
            - ‚úì Aucune intervention n√©cessaire
            - ‚úì Continuer la surveillance normale
            - ‚úì Prochain contr√¥le pr√©vu dans le planning habituel
            """)
        else:
            st.error("""
            ‚ùå **D√©faillance de la valve d√©tect√©e**
            
            **Actions URGENTES recommand√©es :**
            - üî¥ Arr√™t du syst√®me et inspection imm√©diate
            - üîß V√©rifier les joints et le m√©canisme de commutation
            - üìã Planifier une maintenance corrective
            - üìä Analyser l'historique des derniers cycles
            - üë∑ Contacter l'√©quipe de maintenance
            """)
        
        # Niveau de confiance
        if confidence < 0.7:
            st.warning(f"""
            ‚ö†Ô∏è **Attention : Confiance mod√©r√©e ({confidence*100:.1f}%)**
            
            Le mod√®le n'est pas tr√®s s√ªr de sa pr√©diction. Il est recommand√© de :
            - Effectuer une inspection visuelle
            - Lancer une nouvelle analyse avec plus de cycles
            - Consulter un expert en maintenance
            """)
        elif confidence >= 0.9:
            st.success(f"""
            ‚úÖ **Confiance √©lev√©e ({confidence*100:.1f}%)**
            
            Le mod√®le est tr√®s s√ªr de sa pr√©diction. Vous pouvez agir en cons√©quence.
            """)

# ============================================================================
# FOOTER
# ============================================================================

st.sidebar.markdown("---")
st.sidebar.markdown("""
<div style='text-align: center; padding: 1rem;'>
    <p style='font-size: 0.8rem; color: #666;'>
    <b>Valve Prediction System v2.0</b><br>
    ¬© 2025 - Maintenance Pr√©dictive<br>
    Powered by ZADI ALI
    </p>
</div>
""", unsafe_allow_html=True)